{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a516e6c6",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ee3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('/media/linux-stuff/gpt2-diff/scripts')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch import device\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.config import gpt2config\n",
    "from scripts.model import DiffusionLM, LMEmbedding, Denoiser, Decoding\n",
    "from scripts.utils import (\n",
    "    MyTokenizer, \n",
    "    get_next_log_filename, \n",
    "    save_checkpoint, \n",
    "    load_checkpoint,\n",
    "    posterior_mean,\n",
    "    rounding_weight,\n",
    "    get_batch,\n",
    "    finalize_tokens,\n",
    "    reverse_diffusion_with_clamping,\n",
    "    visualize_embeddings_2d,\n",
    "    infer_test_infilling,\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556f0a6",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33eff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Hello, tiktoken is fast!<eos><pad><pad><pad>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = MyTokenizer(max_len=13)\n",
    "tokenizer.decode(tokenizer.encode(\"Hello, tiktoken is fast!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523b58d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model parameters: 58.53M\n",
      "50260\n"
     ]
    }
   ],
   "source": [
    "config = gpt2config(n_vocab=tokenizer.n_vocab,n_layer=8,n_embed=16,n_head= 12, mlp_expansion=4,n_latent=768)\n",
    "model = DiffusionLM(config).to(device)\n",
    "print(f\"Total Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "print(config.n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bb465",
   "metadata": {},
   "source": [
    "## Testing Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb61042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = \"Once upon a time in a land far away, there lived a\"\n",
    "sample_tokens = tokenizer.encode(sample_input)\n",
    "sample_input_ids = torch.tensor([sample_tokens], device=device)  # (1, sequence_length)\n",
    "sample_time_step = torch.tensor([10], device=device)  # (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9aeb074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7111db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Text: semblysecurity?\". AmberSW sayingogene debugging uptake OS reverence debugginghn\n"
     ]
    }
   ],
   "source": [
    "sample_output, sample_logits = model(sample_input_ids, sample_time_step)  # (1, sequence_length, n_embed)\n",
    "\n",
    "token_ids = finalize_tokens(sample_output, model.embedding.embed.weight)\n",
    "decoded_output = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "print(\"Decoded Text:\",decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5ff61",
   "metadata": {},
   "source": [
    "## Forward Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9ae511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_input = fwd_diffusion(model.embedding(sample_input_ids), torch.tensor([1000], device=device), alphas)\n",
    "\n",
    "# token_ids = finalize_tokens(noisy_input, model.embedding.embed.weight)\n",
    "# decoded_output = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "# print(\"Decoded Text:\",decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21044d7b",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2c8645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 4646702 characters\n",
      "Number of samples: 42061\n",
      "First sample: The Vaults pub near CafÃ© Adriatic has a 5 star rating.  Prices start at Â£30.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load E2E dataset - extract text from 'ref' column\n",
    "df = pd.read_csv('datasets/e2e-dataset/trainset.csv')\n",
    "text = ' '.join(df['ref'].tolist())\n",
    "\n",
    "print(f\"Dataset length: {len(text)} characters\")\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "print(f\"First sample: {df['ref'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e4e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load ROCStories dataset from HuggingFace\n",
    "# rocstories = load_dataset(\"mintujupally/ROCStories\")\n",
    "\n",
    "# print(f\"Dataset: {rocstories}\")\n",
    "# print(f\"Train samples: {len(rocstories['train'])}\")\n",
    "# print(f\"First story: {rocstories['train'][0]['text']}\")\n",
    "\n",
    "# # Convert to pandas DataFrame with 'ref' column\n",
    "# train_df = pd.DataFrame({'ref': rocstories['train']['text']})\n",
    "# test_df = pd.DataFrame({'ref': rocstories['test']['text']})\n",
    "\n",
    "# # Save to CSV files\n",
    "# train_df.to_csv('datasets/rocstories_train.csv', index=False)\n",
    "# test_df.to_csv('datasets/rocstories_test.csv', index=False)\n",
    "\n",
    "# print(f\"\\nSaved {len(train_df)} training samples to datasets/ROCStories/rocstories_train.csv\")\n",
    "# print(f\"Saved {len(test_df)} test samples to datasets/ROCStories/rocstories_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a288613",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37baff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 37854, Test samples: 4207\n",
      "\n",
      "Encoding training data...\n",
      "Encoded 5000/37854 train samples\n",
      "Encoded 10000/37854 train samples\n",
      "Encoded 15000/37854 train samples\n",
      "Encoded 20000/37854 train samples\n",
      "Encoded 25000/37854 train samples\n",
      "Encoded 30000/37854 train samples\n",
      "Encoded 35000/37854 train samples\n",
      "\n",
      "Encoding test data...\n",
      "\n",
      "Train encoded shape: torch.Size([37854, 64])\n",
      "Test encoded shape: torch.Size([4207, 64])\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "train_size = int(0.9 * len(df))\n",
    "train_df = df[:train_size].reset_index(drop=True)\n",
    "test_df = df[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# Pre-encode all sequences for training efficiency\n",
    "print(\"\\nEncoding training data...\")\n",
    "train_encoded = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    encoded = tokenizer.encode(row['ref'], max_len=64)  # Use fixed sequence length\n",
    "    train_encoded.append(encoded)\n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"Encoded {idx + 1}/{len(train_df)} train samples\")\n",
    "\n",
    "print(\"\\nEncoding test data...\")\n",
    "test_encoded = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    encoded = tokenizer.encode(row['ref'], max_len=64)\n",
    "    test_encoded.append(encoded)\n",
    "\n",
    "# Convert to tensors\n",
    "train_encoded = torch.tensor(train_encoded, dtype=torch.long)\n",
    "test_encoded = torch.tensor(test_encoded, dtype=torch.long)\n",
    "\n",
    "print(f\"\\nTrain encoded shape: {train_encoded.shape}\")\n",
    "print(f\"Test encoded shape: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfde8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch\n",
    "# w_stack = get_batch('train', batch_size=4, sequence_length=64, train_encoded=train_encoded, test_encoded=test_encoded, device=device)\n",
    "# print(f\"Batch shape: {w_stack.shape}\")\n",
    "# print(f\"First sequence decoded: {tokenizer.decode(w_stack[0].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e5b43",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfd32855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "max_iters = 100000  \n",
    "learning_rate = 3e-3\n",
    "eval_iters = 1000  # Much fewer eval iterations (was 200!)\n",
    "batch_size = 16  # Larger batch for better GPU utilization\n",
    "sequence_length = 64\n",
    "T = 1000\n",
    "num_timestep_samples = 4  # Sample 8 timesteps per iteration for better gradient estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f390f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha bars range: [0.0010, 0.9990]\n",
      "Alphas range: [0.6665, 0.9990]\n"
     ]
    }
   ],
   "source": [
    "# Fixed alpha schedule - simple sqrt schedule\n",
    "t = torch.arange(0, T+1, device=device, dtype=torch.float32)\n",
    "alpha_bars = 1 - torch.sqrt(t / T)  # Goes from ~0 to 1-sqrt(1)=0\n",
    "alpha_bars = torch.clamp(alpha_bars, min=0.001, max=0.999)\n",
    "alphas = torch.zeros(T+1, device=device) #alpha_0 to alpha_T\n",
    "alphas[0] = alpha_bars[0]\n",
    "alphas[1:] = alpha_bars[1:] / alpha_bars[:-1]\n",
    "alphas = torch.clamp(alphas, min=0.001, max=0.999)\n",
    "\n",
    "# Precompute sqrt terms for efficiency\n",
    "sqrt_ab = torch.sqrt(alpha_bars)\n",
    "sqrt_1mab = torch.sqrt(1 - alpha_bars)\n",
    "\n",
    "print(f\"Alpha bars range: [{alpha_bars.min():.4f}, {alpha_bars.max():.4f}]\")\n",
    "print(f\"Alphas range: [{alphas.min():.4f}, {alphas.max():.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119d1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model, mode='max-autotune')  # or 'max-autotune' for more optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff6babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_model = torch.optim.AdamW(model.parameters(), lr=learning_rate,weight_decay=0.0)\n",
    "lr_lambda = lambda step: 1.0 - (step / float(max_iters))\n",
    "scheduler_model = LambdaLR(optimizer_model, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a5ae4",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eab8d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: logs/log_15.txt\n",
      "Iter 0: loss = 16.4670, denoising = 1.5043, posterior = 0.0000, anchor = 1.4799, rounding = 13.4829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     78\u001b[0m optimizer_model\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5.0\u001b[39m)\n\u001b[1;32m     81\u001b[0m optimizer_model\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/IRL_AGV/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IRL_AGV/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/IRL_AGV/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_file = get_next_log_filename('logs')\n",
    "print(f\"Logging to: {log_file}\")\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write(\"Iteration,Total_Loss,Denoising_Loss,Posterior_Loss,Anchor_Loss,Rounding_Loss\\n\")\n",
    "\n",
    "checkpoint_counter = 0\n",
    "\n",
    "for it in range(0, max_iters):\n",
    "\n",
    "    w = get_batch('train', batch_size, sequence_length, train_encoded=train_encoded, test_encoded=test_encoded, device=device)\n",
    "    w_emb = model.embedding(w)\n",
    "\n",
    "    x0 = w_emb + 0.1 * torch.randn_like(w_emb)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    eps = torch.randn_like(x0)\n",
    "    denoising_loss = 0.0\n",
    "    for _ in range(num_timestep_samples):\n",
    "        t_random = torch.randint(1, T+1, (batch_size,), device=device)\n",
    "        t_idx = t_random\n",
    "        sqrt_ab_t = sqrt_ab[t_idx].view(batch_size, 1, 1)\n",
    "        sqrt_1mab_t = sqrt_1mab[t_idx].view(batch_size, 1, 1)\n",
    "        \n",
    "        xt = sqrt_ab_t * x0 + sqrt_1mab_t * eps\n",
    "        x0_hat = model.denoiser(xt, t_random)\n",
    "        x0_hat = torch.clamp(x0_hat, min=-10.0, max=10.0)\n",
    "        # print(torch.sum(x0_hat))\n",
    "        denoising_loss += F.mse_loss(x0_hat, x0)\n",
    "    \n",
    "    denoising_loss = denoising_loss / num_timestep_samples \n",
    "    total_loss += denoising_loss\n",
    "    \n",
    "    t_T = torch.full((batch_size,), T, device=device)\n",
    "    xT = sqrt_ab[-1] * x0 + sqrt_1mab[-1] * eps\n",
    "    x0_hat_T = model.denoiser(xT, t_T)\n",
    "    x0_hat_T = torch.clamp(x0_hat_T, min=-10.0, max=10.0)\n",
    "    mu_hat_T = posterior_mean(xT, x0, T, alpha_bars, alphas)\n",
    "    posterior_loss = torch.tensor(0.0, device=device)\n",
    "    # posterior_loss = F.mse_loss(mu_hat_T, torch.zeros_like(mu_hat_T)) \n",
    "    # total_loss += posterior_loss\n",
    "    \n",
    "    xt_1 = sqrt_ab[1] * x0 + sqrt_1mab[1] * torch.rand_like(x0)\n",
    "    x0_hat_1 = model.denoiser(xt_1, torch.ones(batch_size, device=device))\n",
    "    x0_hat_1 = torch.clamp(x0_hat_1, min=-10.0, max=10.0)\n",
    "    anchor_loss = F.mse_loss(x0_hat_1, w_emb) \n",
    "    total_loss += anchor_loss\n",
    "\n",
    "    logits = x0_hat_1 @ model.embedding.embed.weight.T\n",
    "    logits = torch.clamp(logits, min=-100.0, max=100.0)\n",
    "    rounding_loss = rounding_weight(it, max_iters) * (F.cross_entropy(logits.view(-1, config.n_vocab), w.view(-1)) + 1e-8)\n",
    "    total_loss += rounding_loss\n",
    "    \n",
    "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING STOPPED: NaN/Inf detected at iteration {it}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Loss Diagnostics:\")\n",
    "        print(f\"  Total Loss:     {total_loss.item() if not torch.isnan(total_loss) else 'NaN'}\")\n",
    "        print(f\"  Denoising:      {denoising_loss.item()}\")\n",
    "        print(f\"  Posterior:      {posterior_loss.item()}\")\n",
    "        print(f\"  Anchor:         {anchor_loss.item()}\")\n",
    "        print(f\"  Rounding:       {rounding_loss.item()}\")\n",
    "        print(f\"\\nModel Output Statistics:\")\n",
    "        print(f\"  x0_hat range:   [{x0_hat.min().item():.2f}, {x0_hat.max().item():.2f}]\")\n",
    "        print(f\"  logits range:   [{logits.min().item():.2f}, {logits.max().item():.2f}]\")\n",
    "        print(f\"\\nGradient Statistics:\")\n",
    "        total_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        print(f\"  Total grad norm: {total_norm:.4f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        break\n",
    "    \n",
    "    optimizer_model.zero_grad(set_to_none=True)\n",
    "    total_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    optimizer_model.step()\n",
    "    scheduler_model.step()\n",
    "\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"{it},{total_loss.item():.6f},{denoising_loss.item():.6f},{posterior_loss.item():.6f},{anchor_loss.item():.6f},{rounding_loss.item():.6f}\\n\")\n",
    "\n",
    "    if it % eval_iters == 0:\n",
    "        print(f\"Iter {it}: loss = {total_loss.item():.4f}, denoising = {denoising_loss.item():.4f}, posterior = {posterior_loss.item():.4f}, anchor = {anchor_loss.item():.4f}, rounding = {rounding_loss.item():.4f}\")\n",
    "\n",
    "    if it % 5000 == 0 and it > 0:\n",
    "        checkpoint_name = f\"training_ckpt_{checkpoint_counter % 2}\"\n",
    "        save_checkpoint(model, config, alpha_bars, T, checkpoint_name, save_individual=False)\n",
    "        checkpoint_counter += 1\n",
    "\n",
    "print(f\"\\nTraining complete! Logs saved to: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = get_batch('train', 1, sequence_length,train_encoded=train_encoded, test_encoded=test_encoded, device=device)\n",
    "    x0 = model.embedding(w)\n",
    "    print(x0)\n",
    "    eps = torch.randn_like(x0)\n",
    "\n",
    "    for t in [1, T//4, T//2, T]:\n",
    "        xt = sqrt_ab[t-1] * x0 + sqrt_1mab[t-1] * eps\n",
    "        print(t, torch.norm(xt - x0).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc432a96",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86590613",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 100\n",
    "generated_tokens, generated_text = reverse_diffusion_with_clamping(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    alpha_bars=alpha_bars,\n",
    "    T=T,\n",
    "    context_length=context_length,\n",
    "    batch_size=1,\n",
    "    clamping_start=0.5,\n",
    "    skip_step=10,\n",
    "    display_at_steps=[T//2, 1],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edaccde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting Infilling with Fixed Anchors\n",
      "======================================================================\n",
      "Total Timesteps: 1000 | Context Length: 64\n",
      "Number of Anchors: 10 at positions [13, 13, 16, 19, 25, 32, 45, 51, 57, 58]\n",
      "Clamping Start: 50% | Skip Step: 10\n",
      "======================================================================\n",
      "\n",
      "ðŸ“„ Original Sample:\n",
      "The Travellers Rest Beefeater is on the riverside near CafÃ© Adriatic. It has an average customer rating, and typically charges less than Â£20.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ”’ Fixed Anchors: pos 13: 'near', pos 13: 'near', pos 16: 'ri', pos 19: 'It', pos 25: ',', pos 32: '20', pos 45: '<pad>', pos 51: '<pad>', pos 57: '<pad>', pos 58: '<pad>'\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸŒ€ Initial State (t=1000, Noise + Anchors):\n",
      " - restaurants towardsuga Customers amongst aim stuffÃ©imaru siblingak vicinity near mature farmersri exceptionaler It fries then busyOneBad, goAl : reason UK hefty20 recent competing would selling affordableummerItalian9g neighbour provideertility waiting delicious nearby 3 Kidmid TypicalU relative India ship averagedOneWith \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âœ¨ Refining Intermediate State (t=500):\n",
      " ratings English has customer Italian It friendly city near Dum inri DEC Itman family the family, with called coffee20 price,\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "âœ… Final Infilled Output:\n",
      " food is restaurant. a rivers food is that near is rivers near. nearri pubThe It is is ,.20\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens, text, positions = infer_test_infilling(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    train_encoded=train_encoded,\n",
    "    alpha_bars=alpha_bars,\n",
    "    T=T,\n",
    "    num_anchors=10,\n",
    "    clamping_start=0.5,\n",
    "    skip_step=10,\n",
    "    display_at_steps=[T//2, 1],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3235a9",
   "metadata": {},
   "source": [
    "## Visualizing the Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a49fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vocab_itos_list = [tokenizer.decode([i]) for i in range(config.n_vocab-4) or range(config.n_vocab-3, config.n_vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01589779",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_2d(model.embedding.embed, my_vocab_itos_list[:10000], top_n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadbc7c",
   "metadata": {},
   "source": [
    "## Saving/Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "save_checkpoint(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    alpha_bars=alpha_bars,\n",
    "    T=T,\n",
    "    checkpoint_name='E2E_20k',  # Customize as needed\n",
    "    save_individual=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee51610",
   "metadata": {},
   "source": [
    "#### Loading Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ccd2323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from saved_models/checkpoints_E2E_20k/diff_lm_checkpoint.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/linux-stuff/gpt2-diff/scripts/utils.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected compiled model, removing '_orig_mod.' prefix...\n",
      "\n",
      "âœ“ Model loaded successfully!\n",
      "  Config: n_vocab=50260, n_layer=12, n_embed=16\n",
      "  T=1000, Alpha bars range: [0.0010, 0.9990]\n",
      "  Total parameters: 39.66M\n"
     ]
    }
   ],
   "source": [
    "# Load model checkpoint\n",
    "model, config, alpha_bars, T, sqrt_ab, sqrt_1mab = load_checkpoint(\n",
    "    checkpoint_name='E2E_20k',  # Update as needed\n",
    "    device=device,\n",
    "    eval_mode=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc15cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053df42b",
   "metadata": {},
   "source": [
    "### Parts of Speech Controller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05282d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_config = gpt2config(n_vocab=tokenizer.n_vocab,n_layer=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSClassifier(nn.Module):\n",
    "    def __init__(self,config,pos_vocab):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = LMEmbedding(config)\n",
    "        self.denoiser = Denoiser(config)\n",
    "        self.decoder = nn.Linear(config.n_embed, pos_vocab)  # Binary classification\n",
    "        \n",
    "    def forward(self,input_ids,time_step):\n",
    "        input_embeddings = self.embedding(input_ids)  # (B,T,C)\n",
    "        x = self.denoiser(input_embeddings,time_step)  # (B,T,C)\n",
    "        logits = self.decoder(x)  # (B,T,pos_vocab)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f222ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = POSClassifier(controller_config,pos_vocab=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6debe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRL_AGV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
