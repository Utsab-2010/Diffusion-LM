{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a516e6c6",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/media/linux-stuff/gpt2-diff/scripts')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch import device\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.config import gpt2config\n",
    "from scripts.model import DiffusionLM, LMEmbedding, Denoiser, Decoding\n",
    "from scripts.utils import (\n",
    "    MyTokenizer, \n",
    "    get_next_log_filename, \n",
    "    save_checkpoint, \n",
    "    load_checkpoint,\n",
    "    posterior_mean,\n",
    "    rounding_weight,\n",
    "    get_batch,\n",
    "    finalize_tokens,\n",
    "    reverse_diffusion_with_clamping,\n",
    "    visualize_embeddings_2d,\n",
    "    fwd_diffusion\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556f0a6",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33eff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MyTokenizer(max_len=13)\n",
    "tokenizer.decode(tokenizer.encode(\"Hello, tiktoken is fast!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = gpt2config(n_vocab=tokenizer.n_vocab,n_embed=16,mlp_expansion=4,n_latent=512)\n",
    "model = DiffusionLM(config).to(device)\n",
    "print(f\"Total Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "print(config.n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bb465",
   "metadata": {},
   "source": [
    "## Testing Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb61042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = \"Once upon a time in a land far away, there lived a\"\n",
    "sample_tokens = tokenizer.encode(sample_input)\n",
    "sample_input_ids = torch.tensor([sample_tokens], device=device)  # (1, sequence_length)\n",
    "sample_time_step = torch.tensor([10], device=device)  # (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aeb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7111db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output, sample_logits = model(sample_input_ids, sample_time_step)  # (1, sequence_length, n_embed)\n",
    "\n",
    "token_ids = finalize_tokens(sample_output, model.embedding.embed.weight)\n",
    "decoded_output = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "print(\"Decoded Text:\",decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5ff61",
   "metadata": {},
   "source": [
    "## Forward Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ae511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_input = fwd_diffusion(model.embedding(sample_input_ids), torch.tensor([1000], device=device), alphas)\n",
    "\n",
    "# token_ids = finalize_tokens(noisy_input, model.embedding.embed.weight)\n",
    "# decoded_output = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "# print(\"Decoded Text:\",decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21044d7b",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load E2E dataset - extract text from 'ref' column\n",
    "df = pd.read_csv('datasets/e2e-dataset/trainset.csv')\n",
    "text = ' '.join(df['ref'].tolist())\n",
    "\n",
    "print(f\"Dataset length: {len(text)} characters\")\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "print(f\"First sample: {df['ref'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load ROCStories dataset from HuggingFace\n",
    "# rocstories = load_dataset(\"mintujupally/ROCStories\")\n",
    "\n",
    "# print(f\"Dataset: {rocstories}\")\n",
    "# print(f\"Train samples: {len(rocstories['train'])}\")\n",
    "# print(f\"First story: {rocstories['train'][0]['text']}\")\n",
    "\n",
    "# # Convert to pandas DataFrame with 'ref' column\n",
    "# train_df = pd.DataFrame({'ref': rocstories['train']['text']})\n",
    "# test_df = pd.DataFrame({'ref': rocstories['test']['text']})\n",
    "\n",
    "# # Save to CSV files\n",
    "# train_df.to_csv('datasets/rocstories_train.csv', index=False)\n",
    "# test_df.to_csv('datasets/rocstories_test.csv', index=False)\n",
    "\n",
    "# print(f\"\\nSaved {len(train_df)} training samples to datasets/ROCStories/rocstories_train.csv\")\n",
    "# print(f\"Saved {len(test_df)} test samples to datasets/ROCStories/rocstories_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37baff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_size = int(0.9 * len(df))\n",
    "train_df = df[:train_size].reset_index(drop=True)\n",
    "test_df = df[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# Pre-encode all sequences for training efficiency\n",
    "print(\"\\nEncoding training data...\")\n",
    "train_encoded = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    encoded = tokenizer.encode(row['ref'], max_len=64)  # Use fixed sequence length\n",
    "    train_encoded.append(encoded)\n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"Encoded {idx + 1}/{len(train_df)} train samples\")\n",
    "\n",
    "print(\"\\nEncoding test data...\")\n",
    "test_encoded = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    encoded = tokenizer.encode(row['ref'], max_len=64)\n",
    "    test_encoded.append(encoded)\n",
    "\n",
    "# Convert to tensors\n",
    "train_encoded = torch.tensor(train_encoded, dtype=torch.long)\n",
    "test_encoded = torch.tensor(test_encoded, dtype=torch.long)\n",
    "\n",
    "print(f\"\\nTrain encoded shape: {train_encoded.shape}\")\n",
    "print(f\"Test encoded shape: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch\n",
    "w_stack = get_batch('train', batch_size=4, sequence_length=64, train_encoded=train_encoded, test_encoded=test_encoded, device=device)\n",
    "print(f\"Batch shape: {w_stack.shape}\")\n",
    "print(f\"First sequence decoded: {tokenizer.decode(w_stack[0].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e5b43",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd32855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "max_iters = 100000  \n",
    "learning_rate = 3e-3\n",
    "eval_iters = 1000  # Much fewer eval iterations (was 200!)\n",
    "batch_size = 16  # Larger batch for better GPU utilization\n",
    "sequence_length = 64\n",
    "T = 1000\n",
    "num_timestep_samples = 4  # Sample 8 timesteps per iteration for better gradient estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f390f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed alpha schedule - simple sqrt schedule\n",
    "t = torch.arange(0, T+1, device=device, dtype=torch.float32)\n",
    "alpha_bars = 1 - torch.sqrt(t / T)  # Goes from ~0 to 1-sqrt(1)=0\n",
    "alpha_bars = torch.clamp(alpha_bars, min=0.001, max=0.999)\n",
    "alphas = torch.zeros(T+1, device=device) #alpha_0 to alpha_T\n",
    "alphas[0] = alpha_bars[0]\n",
    "alphas[1:] = alpha_bars[1:] / alpha_bars[:-1]\n",
    "alphas = torch.clamp(alphas, min=0.001, max=0.999)\n",
    "\n",
    "# Precompute sqrt terms for efficiency\n",
    "sqrt_ab = torch.sqrt(alpha_bars)\n",
    "sqrt_1mab = torch.sqrt(1 - alpha_bars)\n",
    "\n",
    "print(f\"Alpha bars range: [{alpha_bars.min():.4f}, {alpha_bars.max():.4f}]\")\n",
    "print(f\"Alphas range: [{alphas.min():.4f}, {alphas.max():.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model, mode='max-autotune')  # or 'max-autotune' for more optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_model = torch.optim.AdamW(model.parameters(), lr=learning_rate,weight_decay=0.0)\n",
    "lr_lambda = lambda step: 1.0 - (step / float(max_iters))\n",
    "scheduler_model = LambdaLR(optimizer_model, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a5ae4",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab8d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0578, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0578, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0578, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0578, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0592, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0642, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0756, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0756, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0756, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0756, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0791, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0889, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0879, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0879, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0879, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([16, 64, 16]) torch.Size([16, 64, 16])\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(1.0879, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "log_file = get_next_log_filename('logs')\n",
    "print(f\"Logging to: {log_file}\")\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write(\"Iteration,Total_Loss,Denoising_Loss,Posterior_Loss,Anchor_Loss,Rounding_Loss\\n\")\n",
    "\n",
    "checkpoint_counter = 0\n",
    "\n",
    "for it in range(0, max_iters):\n",
    "\n",
    "    w = get_batch('train', batch_size, sequence_length, train_encoded=train_encoded, test_encoded=test_encoded, device=device)\n",
    "    w_emb = model.embedding(w)\n",
    "\n",
    "    x0 = w_emb + 0.1 * torch.randn_like(w_emb)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    eps = torch.randn_like(x0)\n",
    "    denoising_loss = 0.0\n",
    "    for _ in range(num_timestep_samples):\n",
    "        t_random = torch.randint(1, T+1, (batch_size,), device=device)\n",
    "        t_idx = t_random\n",
    "        sqrt_ab_t = sqrt_ab[t_idx].view(batch_size, 1, 1)\n",
    "        sqrt_1mab_t = sqrt_1mab[t_idx].view(batch_size, 1, 1)\n",
    "        \n",
    "        xt = sqrt_ab_t * x0 + sqrt_1mab_t * eps\n",
    "        x0_hat = model.denoiser(xt, t_random)\n",
    "        x0_hat = torch.clamp(x0_hat, min=-10.0, max=10.0)\n",
    "        denoising_loss += F.mse_loss(x0_hat, x0)\n",
    "    \n",
    "    denoising_loss = denoising_loss / num_timestep_samples + 1e-8\n",
    "    total_loss += denoising_loss\n",
    "    \n",
    "    t_T = torch.full((batch_size,), T, device=device)\n",
    "    xT = sqrt_ab[-1] * x0 + sqrt_1mab[-1] * eps\n",
    "    x0_hat_T = model.denoiser(xT, t_T)\n",
    "    x0_hat_T = torch.clamp(x0_hat_T, min=-10.0, max=10.0)\n",
    "    mu_hat_T = posterior_mean(xT, x0, T, alpha_bars, alphas)\n",
    "    posterior_loss = F.mse_loss(mu_hat_T, torch.zeros_like(mu_hat_T)) + 1e-8\n",
    "    total_loss += posterior_loss\n",
    "    \n",
    "    xt_1 = sqrt_ab[1] * x0 + sqrt_1mab[1] * torch.rand_like(x0)\n",
    "    x0_hat_1 = model.denoiser(xt_1, torch.ones(batch_size, device=device))\n",
    "    x0_hat_1 = torch.clamp(x0_hat_1, min=-10.0, max=10.0)\n",
    "    anchor_loss = F.mse_loss(x0_hat_1, w_emb) + 1e-8\n",
    "    total_loss += anchor_loss\n",
    "\n",
    "    logits = x0_hat_1 @ model.embedding.embed.weight.T\n",
    "    logits = torch.clamp(logits, min=-100.0, max=100.0)\n",
    "    rounding_loss = rounding_weight(it, max_iters) * (F.cross_entropy(logits.view(-1, config.n_vocab), w.view(-1)) + 1e-8)\n",
    "    total_loss += rounding_loss\n",
    "    \n",
    "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING STOPPED: NaN/Inf detected at iteration {it}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Loss Diagnostics:\")\n",
    "        print(f\"  Total Loss:     {total_loss.item() if not torch.isnan(total_loss) else 'NaN'}\")\n",
    "        print(f\"  Denoising:      {denoising_loss.item()}\")\n",
    "        print(f\"  Posterior:      {posterior_loss.item()}\")\n",
    "        print(f\"  Anchor:         {anchor_loss.item()}\")\n",
    "        print(f\"  Rounding:       {rounding_loss.item()}\")\n",
    "        print(f\"\\nModel Output Statistics:\")\n",
    "        print(f\"  x0_hat range:   [{x0_hat.min().item():.2f}, {x0_hat.max().item():.2f}]\")\n",
    "        print(f\"  logits range:   [{logits.min().item():.2f}, {logits.max().item():.2f}]\")\n",
    "        print(f\"\\nGradient Statistics:\")\n",
    "        total_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        print(f\"  Total grad norm: {total_norm:.4f}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        break\n",
    "    \n",
    "    optimizer_model.zero_grad(set_to_none=True)\n",
    "    total_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    optimizer_model.step()\n",
    "    scheduler_model.step()\n",
    "\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"{it},{total_loss.item():.6f},{denoising_loss.item():.6f},{posterior_loss.item():.6f},{anchor_loss.item():.6f},{rounding_loss.item():.6f}\\n\")\n",
    "\n",
    "    if it % eval_iters == 0:\n",
    "        print(f\"Iter {it}: loss = {total_loss.item():.4f}, denoising = {denoising_loss.item():.4f}, posterior = {posterior_loss.item():.4f}, anchor = {anchor_loss.item():.4f}, rounding = {rounding_loss.item():.4f}\")\n",
    "\n",
    "    if it % 5000 == 0 and it > 0:\n",
    "        checkpoint_name = f\"training_ckpt_{checkpoint_counter % 2}\"\n",
    "        save_checkpoint(model, config, alpha_bars, T, checkpoint_name, save_individual=False)\n",
    "        checkpoint_counter += 1\n",
    "\n",
    "print(f\"\\nTraining complete! Logs saved to: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = get_batch('train', 1, sequence_length)\n",
    "    x0 = model.embedding(w)\n",
    "    print(x0)\n",
    "    eps = torch.randn_like(x0)\n",
    "\n",
    "    for t in [1, T//4, T//2, T]:\n",
    "        xt = sqrt_ab[t-1] * x0 + sqrt_1mab[t-1] * eps\n",
    "        print(t, torch.norm(xt - x0).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc432a96",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86590613",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 64\n",
    "generated_tokens, generated_text = reverse_diffusion_with_clamping(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    alpha_bars=alpha_bars,\n",
    "    T=T,\n",
    "    context_length=context_length,\n",
    "    batch_size=1,\n",
    "    clamping_start=0.5,\n",
    "    skip_step=10,\n",
    "    display_at_steps=[T//2, 1],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3235a9",
   "metadata": {},
   "source": [
    "## Visualizing the Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a49fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vocab_itos_list = [tokenizer.decode([i]) for i in range(config.n_vocab-4) or range(config.n_vocab-3, config.n_vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01589779",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_2d(model.embedding.embed, my_vocab_itos_list[:3000], top_n=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadbc7c",
   "metadata": {},
   "source": [
    "## Saving/Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "save_checkpoint(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    alpha_bars=alpha_bars,\n",
    "    T=T,\n",
    "    checkpoint_name='E2E_v2',  # Customize as needed\n",
    "    save_individual=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee51610",
   "metadata": {},
   "source": [
    "#### Loading Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model checkpoint\n",
    "model, config, alpha_bars, T, sqrt_ab, sqrt_1mab = load_checkpoint(\n",
    "    checkpoint_name='0.5k_12k_E2E',  # Update as needed\n",
    "    device=device,\n",
    "    eval_mode=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053df42b",
   "metadata": {},
   "source": [
    "### Parts of Speech Controller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05282d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_config = gpt2config(n_vocab=tokenizer.n_vocab,n_layer=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSClassifier(nn.Module):\n",
    "    def __init__(self,config,pos_vocab):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = LMEmbedding(config)\n",
    "        self.denoiser = Denoiser(config)\n",
    "        self.decoder = nn.Linear(config.n_embed, pos_vocab)  # Binary classification\n",
    "        \n",
    "    def forward(self,input_ids,time_step):\n",
    "        input_embeddings = self.embedding(input_ids)  # (B,T,C)\n",
    "        x = self.denoiser(input_embeddings,time_step)  # (B,T,C)\n",
    "        logits = self.decoder(x)  # (B,T,pos_vocab)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f222ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = POSClassifier(controller_config,pos_vocab=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6debe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRL_AGV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
